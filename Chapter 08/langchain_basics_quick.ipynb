{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7f0263",
   "metadata": {},
   "source": [
    "# LangChain‚ÄØBasics‚ÄØQuick‚ÄØDemo\n",
    "This short notebook installs LangChain, lets you set your OpenAI key, and walks through:\n",
    "1. A **ConversationChain** with memory\n",
    "2. A quick **LLMMathChain** example\n",
    "\n",
    "Run each cell top‚Äëto‚Äëbottom in Colab. Estimated time: ‚è±Ô∏è‚ÄØ5‚ÄØminutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langchain openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e3a8b",
   "metadata": {},
   "source": [
    "## 1‚ÄØ¬∑‚ÄØConfigure your OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# üëâ Replace with your actual key or use Colab secrets\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93727e",
   "metadata": {},
   "source": [
    "## 2‚ÄØ¬∑‚ÄØConversationChain with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3214ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi! I'm working on RFx automation. Can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What's the first step?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bd6df",
   "metadata": {},
   "source": [
    "## 3‚ÄØ¬∑‚ÄØLLMMathChain demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "math_chain.run('What is 17.5% of 23,503?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335fc0d",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "Try your own prompts, tweak the temperature, or bolt on a vector store once this runs without errors. üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
